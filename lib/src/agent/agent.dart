import 'dart:convert';

import 'package:agenix/agenix.dart';
import 'package:agenix/src/static/_pkg_constants.dart';
import 'package:agenix/src/tools/_parser.dart';
import 'package:agenix/src/tools/_tool_runner.dart';
import 'package:flutter/services.dart';

part '_memory_manager.dart';
part '_prompt_builder.dart';

/// Agent is the main class that represents the AI agent.
/// Define the agent with all background knowledge and tools.
class Agent {
  static final Agent _instance = Agent._internal();

  /// Singleton
  factory Agent() => _instance;
  Agent._internal();

  bool _isInitialized = false;

  late final _MemoryManager _memoryManager;
  late final _PromptBuilder _promptBuilder;

  /// The large language model that the agent uses can be any LLM, right now gemini is supported out of the box
  late final LLM llm;
  late final PromptParser _promptParser;
  late final ToolRunner _toolRunner;

  /// Initialize the agent with a data store and LLM, and load the system data.
  /// In the system data you can define the personality of the agent, the name of the agent, and anything else that comes to mind.
  Future<void> init({required DataStore dataStore, required LLM llm}) async {
    if (_isInitialized) {
      throw Exception('Agent is already initialized');
    }
    try {
      _isInitialized = true;

      _memoryManager = _MemoryManager(dataStore: dataStore);
      this.llm = llm;

      String jsonString = await rootBundle.loadString(
        'assets/system_data.json',
      );
      final raw = json.decode(jsonString);
      _promptBuilder = _PromptBuilder(systemPrompt: raw);

      _promptParser = PromptParser();
      _toolRunner = ToolRunner();
    } catch (e) {
      _isInitialized = false;
      throw Exception('Failed to initialize Agent: $e');
    }
  }

  /// Generate a response to the user message.
  /// The response is generated by the LLM based on the context of the conversation.
  /// The context is built from the conversation history and the system data.
  /// The response is then passed to the tool runner to execute any tools that are needed.
  /// The response is then saved to the memory manager.
  /// The response is returned as an AgentMessage object.
  Future<AgentMessage> generateResponse({
    required String convoId,
    required AgentMessage userMessage,
    int memoryLimit = 10,
    Object? metaData,
  }) async {
    try {
      _memoryManager.saveMessage(convoId, userMessage);

      final memoryMessages = await _memoryManager.getContext(
        convoId,
        metaData: metaData,
      );

      final prompt = _promptBuilder.buildTextPrompt(
        memoryMessages: memoryMessages,
        userMessage: userMessage,
      );

      final String rawLLMResponse = await llm.generate(
        prompt: prompt,
        rawData: userMessage.imageData,
      );
      final parsed = _promptParser.parse(rawLLMResponse);
      if (parsed.toolNames.isEmpty) {
        final response = parsed.fallbackResponse ?? kLLMResponseOnFailure;
        final botResponse = AgentMessage(
          content: response,
          isFromAgent: true,
          generatedAt: DateTime.now(),
        );
        _memoryManager.saveMessage(convoId, botResponse);
        return botResponse;
      }

      final toolResponses = await _toolRunner.runTools(parsed);

      // TODO: Add support for tool chaining, right now we are just joining the messages.
      String response = toolResponses.map((r) => r.message).join('\n');

      final botMessage = AgentMessage(
        content: response.isEmpty ? kLLMResponseOnFailure : response,
        isFromAgent: true,
        generatedAt: DateTime.now(),
      );
      _memoryManager.saveMessage(convoId, botMessage);
      return botMessage;
    } catch (e) {
      if (!_isInitialized) {
        throw Exception('Agent is not initialized, please call init() first.');
      }
      return AgentMessage(
        content: kLLMResponseOnFailure,
        isFromAgent: true,
        generatedAt: DateTime.now(),
      );
    }
  }

  /// Use the method to get all the messages in a conversation.
  /// The messages are returned as a list of AgentMessage objects.
  Future<List<AgentMessage>> getMessages({
    required String conversationId,
    Object? metaData,
  }) async {
    return await _memoryManager.dataStore.getMessages(
      conversationId,
      metaData: metaData,
    );
  }

  /// Use the method to get all conversations for a user.
  /// This allows developers to manage conversations and retrieve them as needed.
  Future<List<Conversation>> getAllConversations({
    required String conversationId,
    Object? metaData,
  }) async {
    return await _memoryManager.dataStore.getConversations(
      conversationId,
      metaData: metaData,
    );
  }

  /// Use the method to delete a conversation.
  Future<void> deleteConversation({
    required String conversationId,
    Object? metaData,
  }) async {
    await _memoryManager.dataStore.deleteConversation(
      conversationId,
      metaData: metaData,
    );
  }
}
